{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99e886a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e538d2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe4a68e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model = ChatGroq(model = \"gemma2-9b-it\", temperature = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84e5d60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hi Kunal,\\n\\nThat's awesome! LangChain and OpenAI are powerful tools for building AI agents. \\n\\nI can definitely help you on your journey. To give you the best guidance, tell me more about what you're working on:\\n\\n* **What kind of AI agent are you trying to build?** (e.g., a chatbot, a research assistant, a code generator)\\n* **What specific tasks do you want your agent to be able to perform?**\\n* **What's your current level of experience with LangChain and OpenAI?**\\n* **Do you have any specific questions or challenges you're facing?**\\n\\nThe more information you provide, the better I can assist you. \\n\\nI'm excited to see what you create!\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 166, 'prompt_tokens': 29, 'total_tokens': 195, 'completion_time': 0.301818182, 'prompt_time': 0.0014124, 'queue_time': 0.069841038, 'total_time': 0.303230582}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--578f6469-5b90-4074-9850-db545a7b9e61-0', usage_metadata={'input_tokens': 29, 'output_tokens': 166, 'total_tokens': 195})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "model.invoke([HumanMessage(content = \"Hi My name is Kunal, I am learning to build AI agents using langchain and openai\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72abaca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Yes, I do! You're Kunal, and you're learning to build AI agents using LangChain and OpenAI.  \\n\\nWhat can I help you with today? Are you working on a specific project or do you have a question about LangChain or OpenAI?\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 60, 'prompt_tokens': 190, 'total_tokens': 250, 'completion_time': 0.109090909, 'prompt_time': 0.004535819, 'queue_time': 0.093048297, 'total_time': 0.113626728}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--a4b7b365-2b3f-4550-ab24-64d1c411f1c0-0', usage_metadata={'input_tokens': 190, 'output_tokens': 60, 'total_tokens': 250})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "model.invoke([\n",
    "    HumanMessage(content = \"Hi My name is Kunal, I am learning to build AI agents using langchain and openai\"),\n",
    "    AIMessage(content = \"I can definitely help you on your journey. To give you the best guidance, tell me more about what you're working on:\\n\\n* **What kind of AI agent are you trying to build?** (e.g., a chatbot, a research assistant, a code generator)\\n* **What specific tasks do you want your agent to be able to perform?**\\n* **What's your current level of experience with LangChain and OpenAI?**\\n* **Do you have any specific questions or challenges you're facing?**\\n\\nThe more information you provide, the better I can assist you. \\n\\nI'm excited to see what you create!\\n\"),\n",
    "    HumanMessage(content = \"Hey do you remember my name and what I am doing?\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "26c3e47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store ={}\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(model,get_session_history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e1a96ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\":{\"session_id\": \"chat1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "053964f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi my name is Kunal, I am learning to build AI agents using LangChain and OpenAI\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "43b8b5e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi Kunal, it's awesome that you're learning about AI agents! \\n\\nLangChain and OpenAI are fantastic tools for this. To help you best, tell me:\\n\\n* **What's your programming background?** (Python experience is helpful for LangChain)\\n* **Have you used any AI models before?** (Like ChatGPT?)\\n* **What kind of agent are you interested in building?** (Chatbot, code helper, something else?)\\n* **Do you have any specific questions or challenges you're facing right now?**\\n\\n\\nThe more you share, the more I can guide you!  Let's build something cool together.\\n\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dbaaf538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Kunal.  ðŸ˜Š  \\n\\nI remember from our earlier conversations!  \\n\\n\\n\\n\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 757, 'total_tokens': 779, 'completion_time': 0.04, 'prompt_time': 0.015351099, 'queue_time': 0.072607305, 'total_time': 0.055351099}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--75111fa0-0a3f-4aef-a60b-b79187a244cf-0', usage_metadata={'input_tokens': 757, 'output_tokens': 22, 'total_tokens': 779})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What is my Name?\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5d3c60d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "config2 = {\"configurable\":{\"session_id\": \"chat2\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fdc1c38f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"As an AI, I have no memory of past conversations and do not know your name. If you'd like to tell me, I'm happy to know! ðŸ˜Š\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 38, 'prompt_tokens': 14, 'total_tokens': 52, 'completion_time': 0.069090909, 'prompt_time': 0.00125131, 'queue_time': 0.092467306, 'total_time': 0.070342219}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--f7ca3434-f476-4a8d-81c3-3af50f2fdd01-0', usage_metadata={'input_tokens': 14, 'output_tokens': 38, 'total_tokens': 52})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What is my Name?\")],\n",
    "    config=config2\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
